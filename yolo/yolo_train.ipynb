{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sUfcA8ZgR2t"
      },
      "source": [
        "# Train YOLO Models in Google Colab\n",
        "**Author:** Evan Juras, [EJ Technology Consultants](https://ejtech.io)\n",
        "\n",
        "**Last updated:** January 3, 2025\n",
        "\n",
        "**GitHub:** [Train and Deploy YOLO Models](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models)\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This notebook uses [Ultralytics](https://docs.ultralytics.com/) to train YOLO11, YOLOv8, or YOLOv5 object detection models with a custom dataset. At the end of this Colab, you'll have a custom YOLO model that you can run on your PC, phone, or edge device like the Raspberry Pi.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/img/yolo-model-demo.gif\" height=\"360\"><br>\n",
        "<i>Custom YOLO candy detection model in action!</i>\n",
        "</p>\n",
        "\n",
        "I created a YouTube video that walks through this guide step by step. I recommend following along with the video while working through this notebook.\n",
        "\n",
        "<p align=center>\n",
        "<a href=\"https://youtu.be/r0RspiLG260\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/doc/Train_YOLO_Thumbnail2.png\" height=\"240\"><br>\n",
        "<i>Click here to go to the video!</i></a>\n",
        "</p>\n",
        "\n",
        "**Important note: This notebook will be continuously updated to make sure it works with newer versions of Ultralytics and YOLO. If you see any differences between the YouTube video and this notebook, always follow the notebook!**\n",
        "\n",
        "### Working in Colab\n",
        "Colab provides a virtual machine in your browser complete with a Linux OS, filesystem, Python environment, and best of all, a free GPU. We'll install PyTorch and Ultralytics in this environment and use it to train our model. Simply click the Play button on sections of code in this notebook to execute them on the virtual machine.\n",
        "\n",
        "### Navigation\n",
        "To navigate this notebook, use the table of contents in the left sidebar to jump from section to section.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NW7LLv_QPOO"
      },
      "source": [
        "**Verify NVIDIA GPU Availability**\n",
        "\n",
        "Make sure you're using a GPU-equipped machine by going to \"Runtime\" -> \"Change runtime type\" in the top menu bar, and then selecting one of the GPU options in the Hardware accelerator section. Click Play on the following code block to verify that the NVIDIA GPU is present and ready for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfaWho47RGDf"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIHu25pnjjJ1"
      },
      "source": [
        "#1.&nbsp;Gather and Label Training Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6Y1vBiRjpcq"
      },
      "source": [
        "Before we start training, we need to gather and label images that will be used for training the object detection model. A good starting point for a proof-of-concept model is 200 images. The training images should have random objects in the image along with the desired objects, and should have a variety of backgrounds and lighting conditions.\n",
        "\n",
        "There are a couple options for gathering images:\n",
        "\n",
        "\n",
        "*   Build a custom dataset by taking your own pictures of the objects and labeling them (this typically results in the best performance)\n",
        "*   Find a pre-made dataset from sources like [Roboflow Universe](), [Kaggle](), or [Google Images V7]()\n",
        "\n",
        "\n",
        "If you want to build your own dataset, there are several tools available for labeling images. One good option is [Label Studio](https://labelstud.io/?utm_source=youtube&utm_medium=video&utm_campaign=edjeelectronics), a free and open-source labeling tool that has a simple workflow while providing capabilities for more advanced features. My YouTube video that walks through this notebook (link to be added soon) shows how to label images with Label Studio.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/doc/label-studio-example.PNG\" height=\"380\"><br>\n",
        "<i>Example of a candy image labeled with Label Studio.</i>\n",
        "</p>\n",
        "\n",
        "If you used Label Studio to label and export the images, they'll be exported in a `project.zip` file that contains the following:\n",
        "\n",
        "- An `images` folder containing the images\n",
        "- A `labels` folder containing the labels in YOLO annotation format\n",
        "- A `classes.txt` labelmap file that contains all the classes\n",
        "- A `notes.json` file that contains info specific to Label Studio (this file can be ignored)\n",
        "\n",
        "If you obtained your dataset from another source (like Roboflow Universe) or used another tool to label your dataset, make sure the files are organized in the same folder structure.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/doc/zipped-data-example.png\" height=\"\"><br>\n",
        "<i>Organize your data in the folders shown here. See my <a href=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/candy_data_06JAN25.zip\">Candy Detection Dataset</a> for an example.</i>\n",
        "</p>\n",
        "\n",
        "Once you've got your dataset built, put into the file structure shown above, and zipped into `data.zip`, you're ready to move on to the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eDhuvzDfIFS"
      },
      "source": [
        "# 2.&nbsp;Upload Image Dataset and Prepare Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_0c110fOiz"
      },
      "source": [
        "Next, we'll upload our dataset and prepare it for training with YOLO. We'll split the dataset into train and validation folders, and we'll automatically generate the configuration file for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwKAqFIQSBpn"
      },
      "source": [
        "## 2.1 Upload images\n",
        "\n",
        "First, we need to upload the dataset to Colab. Here are a few options for moving the `data` folder into this Colab instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoPjqW6AYebn"
      },
      "source": [
        "Ultralytics requires a particular folder structure to store training data for models. Ultralytics requires a particular folder structure to store training data for models. The root folder is named “data”. Inside, there are two main folders:\n",
        "\n",
        "*   **Train**: These are the actual images used to train the model. In one epoch of training, every image in the train set is passed into the neural network. The training algorithm adjusts the network weights to fit the data in the images.\n",
        "\n",
        "\n",
        "*   **Validation**: These images are used to check the model's performance at the end of each training epoch.\n",
        "\n",
        "In each of these folders is a “images” folder and a “labels” folder, which hold the image files and annotation files respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8X62eFTugosf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset directory structure...\n",
            "Directory structure created:\n",
            "  /teamspace/studios/this_studio/yolo_model/dataset\n",
            "  ├── train/\n",
            "  │   ├── images/\n",
            "  │   └── labels/\n",
            "  └── val/\n",
            "      ├── images/\n",
            "      └── labels/\n",
            "\n",
            "Processing Train split...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train split: 3650 files processed, 0 files skipped\n",
            "\n",
            "Processing Validation split...\n",
            "Validation split: 419 files processed, 0 files skipped\n",
            "\n",
            "==================================================\n",
            "Dataset conversion completed!\n",
            "==================================================\n",
            "Train set: 3650 images, 3650 labels\n",
            "Validation set: 419 images, 419 labels\n",
            "Total: 4069 images, 4069 labels\n",
            "\n",
            "Dataset saved to: /teamspace/studios/this_studio/yolo_model/dataset\n",
            "\n",
            "Class mapping used:\n",
            "  0: bad_weld\n",
            "  1: good_weld\n"
          ]
        }
      ],
      "source": [
        "!python dataset_formatter.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2L2qGCJzwY9"
      },
      "source": [
        "# 3.&nbsp;Install Requirements (Ultralytics)\n",
        "\n",
        "Next, we'll install the Ultralytics library in this Google Colab instance. This Python library will be used to train the YOLO model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMEDk5byzxY5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (8.3.192)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (3.8.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (6.1.1)\n",
            "Requirement already satisfied: py-cpuinfo in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: polars in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (1.33.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.8.61)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuZoMkSFN9XG"
      },
      "source": [
        "# 4.&nbsp;Configure Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5Kdh0GmQHS"
      },
      "source": [
        "There's one last step before we can run training: we need to create the Ultralytics training configuration YAML file. This file specifies the location of your train and validation data, and it also defines the model's classes. An example configuration file model is available [here](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco128.yaml).\n",
        "\n",
        "Run the code block below to automatically generate a `data.yaml` configuration file. Make sure you have a labelmap file located at `custom_data/classes.txt`. If you used Label Studio or one of my pre-made datasets, it should already be present. If you assembled the dataset another way, you may have to manually create the `classes.txt` file (see [here](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/doc/classes.txt) for an example of how it's formatted)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4letvP7X12ji"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created config file at data.yaml\n",
            "\n",
            "File contents:\n",
            "\n",
            "path: dataset\n",
            "train: train/images\n",
            "val: val/images\n",
            "nc: 2\n",
            "names:\n",
            "- bad\n",
            "- good\n"
          ]
        }
      ],
      "source": [
        "# Python function to automatically create data.yaml config file\n",
        "# 1. Reads \"classes.txt\" file to get list of class names\n",
        "# 2. Creates data dictionary with correct paths to folders, number of classes, and names of classes\n",
        "# 3. Writes data in YAML format to data.yaml\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # Read class.txt to get class names\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # Create data dictionary\n",
        "  data = {\n",
        "      'path': 'dataset',\n",
        "      'train': 'train/images',\n",
        "      'val': 'val/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # Write data to YAML file\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Define path to classes.txt and run function\n",
        "path_to_classes_txt = 'labels.txt'\n",
        "path_to_data_yaml = 'data.yaml'\n",
        "\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myP80_bnTNMi"
      },
      "source": [
        "# 5.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfKspYasCzC8"
      },
      "source": [
        "## 5.1 Training Parameters\n",
        "Now that the data is organized and the config file is created, we're ready to start training! First, there are a few important parameters to decide on. Visit my article on [Training YOLO Models Locally](https://www.ejtech.io/learn/train-yolo-models) to learn more about these parameters and how to choose them.\n",
        "\n",
        "**Model architecture & size (`model`):**\n",
        "\n",
        "There are several YOLO11 models sizes available to train, including `yolo11n.pt`, `yolo11s.pt`, `yolo11m.pt`, `yolo11l.pt`, and `yolo11xl.pt`. Larger models run slower but have higher accuracy, while smaller models run faster but have lower accuracy. I made a brief YouTube video that compares performance of different YOLO models on a Raspberry Pi 5 and a laptop with a RTX 4050 GPU, [check it out here to get a sense of their speed accuracy](https://youtu.be/_WKS4E9SmkA). If you aren't sure which model size to use, `yolo11s.pt` is a good starting point.\n",
        "\n",
        "You can also train YOLOv8 or YOLOv5 models by substituting `yolo11` for `yolov8` or `yolov5`.\n",
        "\n",
        "\n",
        "**Number of epochs (`epochs`)**\n",
        "\n",
        "In machine learning, one “epoch” is one single pass through the full training dataset. Setting the number of epochs dictates how long the model will train for. The best amount of epochs to use depends on the size of the dataset and the model architecture. If your dataset has less than 200 images, a good starting point is 60 epochs. If your dataset has more than 200 images, a good starting point is 40 epochs.\n",
        "\n",
        "\n",
        "**Resolution (`imgsz`)**\n",
        "\n",
        "Resolution has a large impact on the speed and accuracy of the model: a lower resolution model will have higher speed but less accuracy. YOLO models are typically trained and inferenced at a 640x640 resolution. However, if you want your model to run faster or know you will be working with low-resolution images, try using a lower resolution like 480x480.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V17UjYU5ZQdR"
      },
      "source": [
        "## 5.2 Run Training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQi_hXnUVPr-"
      },
      "source": [
        "Run the following code block to begin training. If you want to use a different model, number of epochs, or resolution, change `model`, `epochs`, or `imgsz`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8bbpob1gTPlo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.194 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.192 🚀 Python-3.10.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA L4, 22491MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=True, amp=True, augment=False, auto_augment=randaugment, batch=22, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=80, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=896, int8=False, iou=0.4, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   1412566  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
            "YOLO11m summary: 231 layers, 20,054,550 parameters, 20,054,534 gradients, 68.2 GFLOPs\n",
            "\n",
            "Transferred 643/649 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3102.5±1100.8 MB/s, size: 236.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /teamspace/studios/this_studio/yolo_model/dataset/train/labels.cache... 3650 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3650/3650 52790377.9it/s 0.0s0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mImageCompression.__init__() got an unexpected keyword argument 'quality_range'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1399.3±1086.0 MB/s, size: 295.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /teamspace/studios/this_studio/yolo_model/dataset/val/labels.cache... 419 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 419/419 1861666.7it/s 0.0ss\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.000515625), 112 bias(decay=0.0)\n",
            "Image sizes 896 train, 896 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 80 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/80      21.5G      1.482      1.236      1.327        112        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:451.0sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.1it/s 4.7s.5sss\n",
            "                   all        419       3769      0.822      0.636      0.651      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/80      20.4G      1.328     0.8529      1.215        155        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:400.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.1it/s 4.7s.5s6s\n",
            "                   all        419       3769      0.438      0.416      0.453      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/80      20.6G      1.328     0.8417      1.211        182        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s7s\n",
            "                   all        419       3769      0.691      0.591      0.592      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/80      20.9G       1.29     0.7894      1.191        161        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:401.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 1.9it/s 5.3s.6sss\n",
            "                   all        419       3769        0.7      0.689      0.629      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/80      21.5G      1.292     0.7778      1.197        178        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.857       0.68      0.672      0.467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/80      20.9G      1.259     0.7392      1.184        173        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s5s\n",
            "                   all        419       3769       0.74       0.63      0.637       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/80      20.9G      1.256     0.7316      1.167        152        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s8s\n",
            "                   all        419       3769      0.704      0.612       0.64      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/80      21.5G      1.253     0.7072      1.172        163        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.986       0.67      0.687      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/80      20.9G      1.249     0.6928      1.166        178        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s6s\n",
            "                   all        419       3769      0.693      0.619      0.627       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/80      20.8G      1.234     0.6856      1.158        164        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.633      0.568      0.626      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/80      21.4G      1.239     0.6854      1.162        152        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s6s\n",
            "                   all        419       3769      0.935      0.659       0.71      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/80      20.9G      1.233     0.6608      1.162        170        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.972      0.674      0.707      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/80      20.9G      1.222     0.6586      1.155        146        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s6s\n",
            "                   all        419       3769      0.847      0.658      0.691       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/80        21G      1.223     0.6556      1.155        165        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s7s\n",
            "                   all        419       3769      0.945      0.636       0.71      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/80      20.7G      1.212     0.6459      1.152        176        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769       0.98      0.632      0.692       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/80      20.8G      1.216     0.6417      1.151        204        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.895       0.57      0.652       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/80      21.4G      1.205     0.6315      1.143        168        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s9s\n",
            "                   all        419       3769      0.889      0.633      0.696      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/80      20.8G      1.198     0.6167      1.143        131        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s2s\n",
            "                   all        419       3769      0.963      0.622      0.702       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/80      20.4G        1.2     0.6258      1.145        159        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s0s\n",
            "                   all        419       3769      0.932      0.664      0.693      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/80      21.5G        1.2     0.6179      1.147        169        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.879      0.631      0.652      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/80      20.9G      1.185     0.6048      1.135        192        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769        0.9      0.666      0.685       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/80      20.8G      1.187     0.5967      1.135        188        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.985      0.608       0.69      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/80      21.4G      1.189     0.6066      1.135        116        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s6s\n",
            "                   all        419       3769      0.969      0.616      0.702      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/80      20.9G      1.192     0.6007       1.14        170        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.934      0.646      0.699      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/80      20.8G      1.186     0.5997      1.132        116        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.981      0.639      0.724      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/80      21.4G      1.183     0.5905      1.132        171        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s7s\n",
            "                   all        419       3769      0.981      0.659      0.708      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/80      20.9G      1.183     0.5976      1.136        152        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.964      0.655      0.701      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/80      20.9G      1.176     0.5784      1.129        150        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.972       0.65      0.732      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/80      21.5G      1.179     0.5883      1.137        156        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s4s\n",
            "                   all        419       3769      0.832       0.63      0.682      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/80      20.9G      1.162     0.5788      1.127        196        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s0s\n",
            "                   all        419       3769      0.778      0.706      0.731      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/80      20.7G      1.166     0.5773      1.128        161        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s7s\n",
            "                   all        419       3769      0.875      0.671      0.724      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/80      21.4G      1.159     0.5706      1.123        164        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s2s\n",
            "                   all        419       3769      0.867      0.726      0.749      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/80      20.9G      1.165     0.5775      1.126        182        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s5s\n",
            "                   all        419       3769      0.878      0.687      0.729       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/80      20.6G      1.159     0.5685      1.127        184        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s5s\n",
            "                   all        419       3769      0.782      0.676      0.725      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/80      21.5G      1.153     0.5568      1.121        165        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.959      0.671      0.712      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/80      20.9G      1.151     0.5665      1.122        136        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.942      0.621      0.697      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/80      20.9G      1.154     0.5611      1.124        160        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.921      0.684       0.71      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/80      21.4G      1.149     0.5521      1.122        179        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s6s\n",
            "                   all        419       3769      0.882      0.721       0.76      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/80      20.9G      1.148     0.5559      1.122        155        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.1it/s 4.7s.5sss\n",
            "                   all        419       3769      0.901      0.739      0.778      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/80      20.9G      1.143     0.5578      1.121        156        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.857      0.743       0.76      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/80      21.5G      1.136     0.5445      1.114        183        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.789      0.764      0.758      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/80      20.9G      1.145     0.5466      1.122        161        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.817      0.699      0.729      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/80      20.9G      1.128     0.5422      1.108        155        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s8s\n",
            "                   all        419       3769       0.89      0.689      0.718      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/80      21.4G       1.13     0.5396      1.116        147        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769       0.93      0.662      0.719      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/80      20.9G      1.134     0.5387      1.117        165        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s6s\n",
            "                   all        419       3769      0.927      0.659      0.733      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/80      20.6G       1.12     0.5314      1.107        166        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.851      0.698      0.751      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/80      21.5G      1.124     0.5318      1.107        138        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s9s\n",
            "                   all        419       3769      0.954      0.669      0.688      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/80      20.6G      1.113      0.524      1.101        183        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s5s\n",
            "                   all        419       3769      0.954      0.732      0.786      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/80      20.9G       1.11     0.5293      1.103        180        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s6s\n",
            "                   all        419       3769      0.894      0.788      0.811       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/80      21.5G      1.109     0.5257      1.099        170        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.853      0.684      0.716      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      51/80      20.9G      1.111     0.5209        1.1        134        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s2s\n",
            "                   all        419       3769      0.822      0.781      0.799      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      52/80      20.9G      1.109     0.5173      1.105        219        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.933      0.682      0.717      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      53/80      21.4G       1.11      0.507        1.1        158        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s7s\n",
            "                   all        419       3769      0.886      0.794      0.806      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      54/80      20.6G      1.109     0.5084      1.096        197        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s5s\n",
            "                   all        419       3769      0.901      0.771      0.817      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      55/80      20.8G      1.104      0.505      1.098        140        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.851      0.829      0.828      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      56/80      21.2G      1.093     0.4988        1.1        154        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.824      0.809      0.812      0.569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      57/80      20.9G      1.092     0.4973      1.095        215        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.939      0.767      0.794      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      58/80      20.8G      1.091     0.4961      1.094        146        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.878      0.735      0.778      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      59/80      21.4G      1.089     0.4983      1.085        182        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s9s\n",
            "                   all        419       3769      0.901      0.762      0.791      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      60/80      20.9G      1.082     0.4929      1.085        159        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s9s\n",
            "                   all        419       3769      0.896      0.742      0.762      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      61/80      20.9G       1.09     0.4927       1.09        173        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.831      0.744      0.772      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      62/80      21.5G       1.08     0.4888      1.089        162        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.865      0.804       0.82      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      63/80      20.9G      1.079     0.4881      1.083         97        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s6s\n",
            "                   all        419       3769      0.884      0.721      0.742      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      64/80      20.9G      1.074     0.4794      1.082        133        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s6s\n",
            "                   all        419       3769      0.903      0.716      0.755      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      65/80      21.4G      1.077     0.4857      1.084        165        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.817      0.705      0.731      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      66/80      20.8G      1.064     0.4766      1.077        153        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769       0.85      0.721      0.735      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      67/80      20.6G      1.061     0.4745      1.074        180        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.928      0.795      0.827      0.578\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      68/80      21.5G      1.059     0.4672      1.069        155        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s7s\n",
            "                   all        419       3769      0.796      0.754      0.759      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      69/80      20.6G      1.062     0.4616      1.073        161        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.857      0.794      0.787       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      70/80      20.6G      1.057     0.4647       1.07        114        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s6s\n",
            "                   all        419       3769      0.856      0.782      0.794       0.55\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mImageCompression.__init__() got an unexpected keyword argument 'quality_range'\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      71/80      21.4G      1.058     0.4281      1.096        107        896: 100% ━━━━━━━━━━━━ 166/166 1.0it/s 2:390.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s4s\n",
            "                   all        419       3769      0.856      0.738       0.77      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      72/80      20.8G       1.05     0.4237      1.093         72        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769      0.868      0.743      0.767      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      73/80      20.8G      1.046     0.4206      1.088        107        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s3s\n",
            "                   all        419       3769       0.89      0.756      0.781      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      74/80      21.4G      1.045     0.4165      1.092         82        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769       0.88      0.827      0.841      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      75/80      20.9G      1.039     0.4172      1.088         68        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s5s\n",
            "                   all        419       3769      0.851      0.769      0.785       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      76/80      20.8G      1.034     0.4105      1.087         76        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s4s\n",
            "                   all        419       3769      0.864      0.738      0.776      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      77/80      21.4G      1.034     0.4071      1.085         87        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s8s\n",
            "                   all        419       3769      0.858      0.756      0.786      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      78/80      20.8G      1.028     0.4027      1.083         86        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.6s.5s7s\n",
            "                   all        419       3769      0.851      0.769      0.789       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      79/80      20.8G      1.026     0.3998      1.077         83        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s5s\n",
            "                   all        419       3769      0.886      0.753      0.783      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      80/80      21.4G      1.023      0.401      1.075         99        896: 100% ━━━━━━━━━━━━ 166/166 1.1it/s 2:380.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 2.2it/s 4.5s.5s6s\n",
            "                   all        419       3769      0.835      0.769      0.786      0.549\n",
            "\n",
            "80 epochs completed in 3.649 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 40.5MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 40.5MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.192 🚀 Python-3.10.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA L4, 22491MiB)\n",
            "YOLO11m summary (fused): 125 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 10/10 1.9it/s 5.2s.5sss\n",
            "                   all        419       3769      0.881      0.827      0.841      0.588\n",
            "                   bad         44        114      0.771      0.675       0.69      0.461\n",
            "                  good        399       3655       0.99      0.979      0.992      0.715\n",
            "Speed: 0.2ms preprocess, 7.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo detect train data=data.yaml model=yolo11m.pt epochs=80 imgsz=896 batch=22 iou=0.4 agnostic_nms=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv0EYWJ5V6mC"
      },
      "source": [
        "The training algorithm will parse the images in the training and validation directories and then start training the model. At the end of each training epoch, the program runs the model on the validation dataset and reports the resulting mAP, precision, and recall. As training continues, the mAP should generally increase with each epoch. Training will end once it goes through the number of epochs specified by `epochs`.\n",
        "\n",
        "> **NOTE:** Make sure to allow training to run to completion, because an optimizer runs at the end of training that strips out unneeded layers from the model.\n",
        "\n",
        "The best trained model weights will be saved in `content/runs/detect/train/weights/best.pt`. Additional information about training is saved in the `content/runs/detect/train` folder, including a `results.png` file that shows how loss, precision, recall, and mAP progressed over each epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo8BJRXeg0Ap"
      },
      "source": [
        "#6.&nbsp;Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX3PTrEPacGY"
      },
      "source": [
        "The model has been trained; now it's time to test it! The commands below run the model on the images in the validation folder and then display the results for the first 10 images. This is a good way to confirm your model is working as expected. Click Play on the blocks below to see how your model performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.192 🚀 Python-3.10.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA L4, 22491MiB)\n",
            "YOLO11m summary (fused): 125 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2714.1±824.5 MB/s, size: 302.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /teamspace/studios/this_studio/yolo_model/dataset/val/labels.cache... 419 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 419/419 2914450.0it/s 0.0s0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 27/27 2.1it/s 12.6s0.4s\n",
            "                   all        419       3769      0.868      0.726      0.749      0.522\n",
            "                   bad         44        114      0.753      0.456      0.505       0.33\n",
            "                  good        399       3655      0.982      0.996      0.992      0.714\n",
            "Speed: 0.8ms preprocess, 12.5ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
            "Saving runs/detect/val/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo val model=runs/detect/train3/weights/best.pt data=data.yaml split=val save_json save_txt save_conf iou=0.4 agnostic_nms=True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PooP5Vjsg2Jn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.170 🚀 Python-3.10.10 torch-2.2.1+cu121 CUDA:0 (NVIDIA L4, 22491MiB)\n",
            "YOLO11m summary (fused): 125 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n",
            "\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=dataset/val/images save=True iou=0.4 agnostic_nms=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEObQqoiGrs"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
